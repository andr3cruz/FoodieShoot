{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Food101-img_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_4AI6AYtlIbb",
        "nDq73-XChRPd",
        "tCkYdfdV8pXO",
        "X34N33Ab5wh8",
        "EiyIwdVI51yx",
        "jhduxNRO623a"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4AI6AYtlIbb",
        "colab_type": "text"
      },
      "source": [
        "# NVIDIA Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt1KX6kGlL5r",
        "colab_type": "code",
        "outputId": "d60e1a5e-76cd-4be4-d07a-86ac8d021df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Feb 29 17:57:10 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDq73-XChRPd",
        "colab_type": "text"
      },
      "source": [
        "# Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpZyrUxghS19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "!pip install pillow\n",
        "!pip install lxml\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install gdown\n",
        "!pip install tensorflow-gpu\n",
        "!pip install keras\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlejbezZhjpu",
        "colab_type": "text"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4waZ8kcTmb_f",
        "colab_type": "text"
      },
      "source": [
        "## Other packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cdHc8ZYms1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwhXdBwOmYrS",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow and Keras Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9DT49P2hljR",
        "colab_type": "code",
        "outputId": "f77bf306-eb21-4ca5-b884-c6c3c48d0f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "\n",
        "print(\"TensorFlow Version: {}\".format(tf.__version__))\n",
        "print(\"GPU: {}\".format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "TensorFlow Version: 2.1.0\n",
            "GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ZlYlnqpduX",
        "colab_type": "text"
      },
      "source": [
        "# Download data and extract it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWSDCVSoo128",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataExtraction():\n",
        "  if 'food-101' in os.listdir():\n",
        "    print('Dataset already exists')\n",
        "  else:\n",
        "    print('Downloading data ...')\n",
        "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "    print('Data downloaded')\n",
        "    print('...\\nBeggining extraction ...')\n",
        "    !tar xzvf food-101.tar.gz\n",
        "    print('Extraction complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMJlSsflpgvd",
        "colab_type": "text"
      },
      "source": [
        "Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUqTOq8wpiJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataExtraction()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAObZCSqrLY-",
        "colab_type": "text"
      },
      "source": [
        "# Analyse the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsTENjC4rST6",
        "colab_type": "text"
      },
      "source": [
        "What's inside:\n",
        "*  This dataset has 101000 images\n",
        "*  It has **101 classification categories**\n",
        "*  Each food has 750 training examples and 250 test samples\n",
        "*  The training data is not entirely clean, containing some noise\n",
        "*  all the images were resized to have a maximum length of 512 pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLs4wphfsAQy",
        "colab_type": "text"
      },
      "source": [
        "What's inside the folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5MzHc7rsE08",
        "colab_type": "code",
        "outputId": "c447a4c9-7a98-40df-b9e7-60e3fbd0e1c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls food-101/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images\tlicense_agreement.txt  meta  README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTa9Z1sseHM",
        "colab_type": "text"
      },
      "source": [
        "The **meta** folder contains text files for train and test\n",
        "*  The **train.txt** has a list of images that belong to the training set\n",
        "*  The **test.txt** has a list of images that belong to the test set\n",
        "*  The **classes.txt** contains the list of all classes of food\n",
        "\n",
        "Have a look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgcOmY6ItD8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Contents of train.txt:')\n",
        "!head food-101/meta/train.txt\n",
        "print('...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_-sK_wetRyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Contents of test.txt:')\n",
        "!head food-101/meta/test.txt\n",
        "print('...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOGvKbRMtVLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Contents of classes.txt:')\n",
        "!head food-101/meta/classes.txt\n",
        "print('...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnfTQccdsJCg",
        "colab_type": "text"
      },
      "source": [
        "The images folder has 101 folders with 1000 images each.\n",
        "\n",
        "Each forlder has images of that class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzWWPWIQsTF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('food-101/images') #list of foods"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Ht28I7to3u",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dxn4G34trR3",
        "colab_type": "text"
      },
      "source": [
        "Visualize the data, showing one image per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLobkkAytuxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataVisualize(rows,cols):\n",
        "  fig, ax = plt.subplots(rows,cols, figsize=(25,25))\n",
        "  fig.suptitle('Showing one random image from each class', y=1.05,fontsize=24)\n",
        "  data_dir = 'food-101/images/'\n",
        "  foods_sorted = sorted(os.listdir(data_dir))\n",
        "  food_id = 0\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      try:\n",
        "        food_selected = foods_sorted[food_id]\n",
        "        food_id += 1\n",
        "      except:\n",
        "        break\n",
        "      if food_selected == '.DS_Store':\n",
        "        continue\n",
        "      #List of all files present in each food category\n",
        "      food_selected_images = os.listdir(os.path.join(data_dir,food_selected))\n",
        "      #Picks one food randomly\n",
        "      food_selected_random = np.random.choice(food_selected_images)\n",
        "      img = plt.imread(os.path.join(data_dir,food_selected,food_selected_random))\n",
        "      ax[i][j].imshow(img)\n",
        "      ax[i][j].set_title(food_selected, pad = 10)\n",
        "  plt.setp(ax, xticks=[],yticks=[])\n",
        "  plt.tight_layout()  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqYK3rBOvGvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataVisualize(17,6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbDgLI4Wv9IN",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBBqbRnawAik",
        "colab_type": "text"
      },
      "source": [
        "## Split data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIAf_OmXwEML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataPrepare(filepath, src, dest):\n",
        "  if os.path.exists(dest):\n",
        "      print('Path already exists.\\nDo you want to continue y/n (all data will be lost)')\n",
        "      inp = input()\n",
        "      if inp == 'y':\n",
        "        print('Replacing data ...')\n",
        "        rmtree(dest)\n",
        "      else:\n",
        "        print('Operation canceled')\n",
        "        return\n",
        "\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath,'r') as txt:\n",
        "    paths = [line.strip() for line in txt.readlines()]\n",
        "    for p in paths:\n",
        "      food = p.split('/')\n",
        "      classes_images[food[0]].append(food[1] + '.jpg')\n",
        "    \n",
        "  for food in classes_images.keys():\n",
        "    print('Copying images into ',food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    \n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print('All done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvdBcP_vxmzE",
        "colab_type": "text"
      },
      "source": [
        "### Create train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGOEb1GRxBir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Creating training data ...')\n",
        "dataPrepare('food-101/meta/train.txt','food-101/images','train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJzPV7H6yAsW",
        "colab_type": "code",
        "outputId": "a2a1d10b-77e1-47de-f696-6207ab9a710c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('Total samples in train folder')\n",
        "!find train -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total samples in train folder\n",
            "75750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7QPrkHbxtRu",
        "colab_type": "text"
      },
      "source": [
        "### Create test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6-zPEDHxvJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Creating testing data ...')\n",
        "dataPrepare('food-101/meta/test.txt','food-101/images','test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjlT2oIBySur",
        "colab_type": "code",
        "outputId": "b1820284-45b2-4579-ac7a-174c326bba63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('Total samples in test folder')\n",
        "!find test -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total samples in test folder\n",
            "25250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWCxlY6iyqCA",
        "colab_type": "text"
      },
      "source": [
        "## Create subset of data with less classes for fast training/experimenting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZeNFGYOy0XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sortedFoods():\n",
        "  data_dir = 'food-101/images/'\n",
        "  foods_sorted = sorted(os.listdir(data_dir))\n",
        "  return foods_sorted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlwTYfHry6-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foods_sorted = sortedFoods()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogr4Kx2OzU_H",
        "colab_type": "text"
      },
      "source": [
        "## Method for creating train_mini and test_mini data samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3grQhOfxzaWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def miniDataset(food_list, src, dest):\n",
        "  if os.path.exists(dest):\n",
        "      print('Path already exists.\\nDo you want to continue y/n (all data will be lost)')\n",
        "      inp = input()\n",
        "      if inp == 'y':\n",
        "        print('Replacing data ...')\n",
        "        rmtree(dest)\n",
        "      else:\n",
        "        print('Operation canceled')\n",
        "        return\n",
        "  os.makedirs(dest)\n",
        "\n",
        "  for food_item in food_list:\n",
        "    print('Copying images into ',food_item)\n",
        "    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKqpDcHj1Ig4",
        "colab_type": "code",
        "outputId": "3678370f-9867-4e03-8d5f-3ac605258593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "food_list = [\n",
        "             'apple_pie',\n",
        "             'baby_back_ribs',\n",
        "             'beef_carpaccio',\n",
        "             'bread_pudding',\n",
        "             'caesar_salad',\n",
        "             'cannoli',\n",
        "             'carrot_cake',\n",
        "             'cheesecake',\n",
        "             'chicken_curry',\n",
        "             'chicken_wings',\n",
        "             'chocolate_cake',\n",
        "             'chocolate_mousse',\n",
        "             'churros',\n",
        "             'cup_cakes',\n",
        "             'donuts',\n",
        "             'dumplings',\n",
        "             'falafel',\n",
        "             'fish_and_chips',\n",
        "             'french_fries',\n",
        "             'french_toast',\n",
        "             'fried_rice',\n",
        "             'garlic_bread',\n",
        "             'grilled_salmon',\n",
        "             'guacamole',\n",
        "             'hot_dog',\n",
        "             'hot_and_sour_soup',\n",
        "             'hummus',\n",
        "             'hamburger',\n",
        "             'ice_cream',\n",
        "             'lasagna',\n",
        "             'macaroni_and_cheese',\n",
        "             'macarons',\n",
        "             'nachos',\n",
        "             'onion_rings',\n",
        "             'oysters',\n",
        "             'pancakes',\n",
        "             'pork_chop',\n",
        "             'poutine',\n",
        "             'ramen',\n",
        "             'ravioli',\n",
        "             'risotto',\n",
        "             'spaghetti_bolognese',\n",
        "             'spaghetti_carbonara',\n",
        "             'steak',\n",
        "             'sushi',\n",
        "             'tacos',\n",
        "             'waffles',\n",
        "             'pizza',\n",
        "             'omelette'\n",
        "]\n",
        "\n",
        "src_train = 'train'\n",
        "src_test = 'test'\n",
        "\n",
        "dest_train = 'train_mini'\n",
        "dest_test = 'test_mini'\n",
        "leng = len(food_list)\n",
        "leng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPP-QUD41qpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Creating mini train data folder')\n",
        "miniDataset(food_list,src_train,dest_train)\n",
        "\n",
        "print('Total number of samples in train_mini:')\n",
        "!find train_mini -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBxPZBW-14sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Creating mini test data folder')\n",
        "miniDataset(food_list,src_test,dest_test)\n",
        "\n",
        "print('Total number of samples in test_mini:')\n",
        "!find test_mini -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd2VvUII2evv",
        "colab_type": "text"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYNFAtSj2jCo",
        "colab_type": "text"
      },
      "source": [
        "## Tunning the **Inception pretrained model** for our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "updCmCQv2rfO",
        "colab_type": "text"
      },
      "source": [
        "Why:\n",
        "*  Keras and other deep learning libraries provide pretrained models so that development is easier (these models might have been training for hours or days)\n",
        "*  These models are deep neural networks with efficient architectures, the user does not need to concern himself with the defenition of the model\n",
        "*  Using  this pretrained models we can use already learned weights and add a few layers on top of it to finetune the model to our specific data\n",
        "*  This helps in faster convergance and saves time and computation when compared to models trainedd from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCkYdfdV8pXO",
        "colab_type": "text"
      },
      "source": [
        "### Step by step functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SACliiCJ3gIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelTune(n_classes,img_width,img_height,train_data_dir,validation_data_dir,nb_trai_samples,nb_validation_samples,batch_size):\n",
        "  train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "  \n",
        "  test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "  \n",
        "  validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "  return train_datagen,test_datagen,train_generator,validation_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X34N33Ab5wh8",
        "colab_type": "text"
      },
      "source": [
        "#### Model Build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2aGt6ae5YDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelBuild():\n",
        "  inception = InceptionV3(weights='imagenet', include_top=False)\n",
        "  x = inception.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  predictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
        "  model = Model(inputs=inception.input, outputs=predictions)\n",
        "  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXiZbmkH5sms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = modelBuild()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiyIwdVI51yx",
        "colab_type": "text"
      },
      "source": [
        "#### Model Train/Fit and save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osiMT6B658Bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelTrain(model,ep,nb_trai_samples,nb_validation_samples,batch_size,train_generator,validation_generator):\n",
        "  checkpointer = ModelCheckpoint(filepath='best_model_3class.hdf5', verbose=1, save_best_only=True)\n",
        "  csv_logger = CSVLogger('history_3class.log')\n",
        "\n",
        "  history = model.fit_generator(train_generator,\n",
        "                    steps_per_epoch = nb_train_samples // batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=nb_validation_samples // batch_size,\n",
        "                    epochs=ep,\n",
        "                    verbose=1,\n",
        "                    callbacks=[csv_logger, checkpointer])\n",
        "  \n",
        "  model.save('model_trained_class.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhduxNRO623a",
        "colab_type": "text"
      },
      "source": [
        "## Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPdrb4w36-Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageClassificationNN():\n",
        "  def __init__(self):\n",
        "    K.clear_session()\n",
        "    print('Model Session initiated')\n",
        "\n",
        "  def modelTune(self,n_classes,img_width,img_height,train_data_dir,validation_data_dir,nb_train_samples,nb_validation_samples,batch_size):\n",
        "    self.n_classes = n_classes\n",
        "    self.nb_train_samples = nb_train_samples\n",
        "    self.nb_validation_samples = nb_validation_samples\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1. / 255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "    \n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "    \n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "      validation_data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "    self.train_datagen = train_datagen\n",
        "    self.test_datagen = test_datagen\n",
        "    self.train_generator = train_generator\n",
        "    self.validation_generator = validation_generator\n",
        "    return train_datagen,test_datagen,train_generator,validation_generator\n",
        "\n",
        "  def modelBuild(self,activation='softmax',loss='categorical_crossentropy', metrics=['accuracy'],units=101):\n",
        "      inception = InceptionV3(weights='imagenet', include_top=False)\n",
        "      x = inception.output\n",
        "      x = GlobalAveragePooling2D()(x)\n",
        "      x = Dense(128,activation='relu')(x)\n",
        "      x = Dropout(0.2)(x)\n",
        "\n",
        "      predictions = Dense(units,kernel_regularizer=regularizers.l2(0.005), activation=activation)(x)\n",
        "      self.model = Model(inputs=inception.input, outputs=predictions)\n",
        "      self.model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=loss, metrics=metrics)\n",
        "      print(self.model.summary)\n",
        "      return self.model\n",
        "\n",
        "  def modelTrain(self,epochs=30):\n",
        "      out_folder = './checkpoints'\n",
        "      if not os.path.exists(out_folder):\n",
        "        os.makedirs(out_folder)\n",
        "      filepath = out_folder + '/model-{epoch:02d}-{val_accuracy:-2f}.hdf5'\n",
        "      checkpointer = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, save_weights_only=False,save_frequency=1)\n",
        "      csv_logger = CSVLogger('history_3class.log')\n",
        "\n",
        "      self.history = self.model.fit(self.train_generator,\n",
        "                        steps_per_epoch=self.nb_train_samples // batch_size,\n",
        "                        validation_data=self.validation_generator,\n",
        "                        validation_steps=self.nb_validation_samples // batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        callbacks=[csv_logger, checkpointer])\n",
        "      \n",
        "      self.model.save('model_trained_class.hdf5')\n",
        "      return self.history, self.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1lAnvJM-2uR",
        "colab_type": "text"
      },
      "source": [
        "# Applying model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msVpMZML8_P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we only have 3 classes in mini samples\n",
        "img_classification = ImageClassificationNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZyZQdEf9Omq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = leng\n",
        "img_width,img_height = 229,229\n",
        "train_data_dir,validation_data_dir = 'train_mini','test_mini'\n",
        "nb_train_samples,nb_validation_samples = 36750, 12250\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlFLT41l9oNW",
        "colab_type": "code",
        "outputId": "370bc33b-2214-42bd-da81-c45201b7e94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_datagen,test_datagen,train_generator,validation_generator = img_classification.modelTune(\n",
        "    n_classes,\n",
        "    img_width,img_height,\n",
        "    train_data_dir,validation_data_dir,\n",
        "    nb_train_samples,nb_validation_samples,\n",
        "    batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 36750 images belonging to 49 classes.\n",
            "Found 12250 images belonging to 49 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS_VGxcy9-Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = img_classification.modelBuild(units=leng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvmhGZFi-XqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history, model = img_classification.modelTrain()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY4deTeVK_u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImLf7_-M3adg",
        "colab_type": "text"
      },
      "source": [
        "# Visualize accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJesjvYt3ec0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_map_3 = train_generator.class_indices\n",
        "class_map_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Xx6R0A3oZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "  \n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jim0u80339Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accuracy(history,'FOOD101-Inceptionv3')\n",
        "plot_loss(history,'FOOD101-Inceptionv3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-pnY5dN3_4h",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-qmzzro4BLv",
        "colab_type": "code",
        "outputId": "8667e8fa-0c98-4016-d749-15bad2305143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "# Loading the best saved model to make predictions\n",
        "K.clear_session()\n",
        "model_best = load_model('model_trained_class.hdf5',compile = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.73 s, sys: 410 ms, total: 5.14 s\n",
            "Wall time: 10.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzEg8rb-F5O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_class(model, images, show = True):\n",
        "  for img in images:\n",
        "    img = image.load_img(img, target_size=(299, 299))\n",
        "    img = image.img_to_array(img)                    \n",
        "    img = np.expand_dims(img, axis=0)         \n",
        "    img /= 255.                                      \n",
        "\n",
        "    pred = model.predict(img)\n",
        "    index = np.argmax(pred)\n",
        "    food_list.sort()\n",
        "    pred_value = food_list[index]\n",
        "    if show:\n",
        "        plt.imshow(img[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.title(pred_value)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ct4FOqjF9g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading images from internet using the URLs\n",
        "!wget -O samosa.jpg http://veggiefoodrecipes.com/wp-content/uploads/2016/05/lentil-samosa-recipe-01.jpg\n",
        "!wget -O applepie.jpg https://acleanbake.com/wp-content/uploads/2017/10/Paleo-Apple-Pie-with-Crumb-Topping-gluten-free-grain-free-dairy-free-15.jpg\n",
        "!wget -O pizza.jpg http://104.130.3.186/assets/itemimages/400/400/3/default_9b4106b8f65359684b3836096b4524c8_pizza%20dreamstimesmall_94940296.jpg\n",
        "!wget -O omelette.jpg https://www.incredibleegg.org/wp-content/uploads/basic-french-omelet-930x550.jpg\n",
        "!wget -O hamburg.jpg https://www.google.com/url?sa=i&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHamburger&psig=AOvVaw2Wp6h2o_vIGkgyRuSdS84-&ust=1583857252187000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCJClyKDmjegCFQAAAAAdAAAAABAD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EAiyaNbGBE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a list of downloaded images and test the trained model\n",
        "images = []\n",
        "images.append('applepie.jpg')\n",
        "images.append('omlett.jfif')\n",
        "images.append('pizza.jfif')\n",
        "images.append('samosa.jpg')\n",
        "images.append('hamb.jfif')\n",
        "predict_class(model_best, images, True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}